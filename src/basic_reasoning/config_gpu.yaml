# Enhanced GPU Configuration for HierRAGMed Basic Reasoning
# File: src/basic_reasoning/config_gpu.yaml
# Optimized for RunPod RTX 4090 GPU environment

# Data directories
data_dir: "data/foundation"
logs_dir: "logs"

# Model configurations
models:
  embedding:
    name: "microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext"
    device: "cuda"
    batch_size: 32  # Increased for GPU
    max_length: 512
    normalize_embeddings: true
    use_medical_embedding: true
    
    # GPU optimizations - FIXED: Remove Flash Attention for BERT
    mixed_precision: true
    compile_model: false  # Disable model compilation for stability
    pin_memory: true
    num_workers: 4
    
    # REMOVED: Flash Attention (not supported by BERT)
    # use_flash_attention: false
    
    # Fallback configuration
    fallback_model: "sentence-transformers/all-MiniLM-L6-v2"
    enable_fallback: true

  llm:
    name: "mistral:7b-instruct"
    base_url: "http://localhost:11434"
    device: "cuda"
    batch_size: 16  # Increased for GPU
    temperature: 0.3  # Lower for more consistent medical answers
    max_tokens: 512
    timeout: 120
    
    # GPU optimizations
    mixed_precision: true
    pin_memory: true

# Hierarchical retrieval configuration
hierarchical_retrieval:
  # Tier configurations
  tier1_top_k: 15  # Increased for GPU
  tier2_top_k: 20  # Increased for GPU  
  tier3_top_k: 10
  
  # Medical enhancements
  medical_entity_boost: 1.2
  clinical_context_window: 3
  enable_evidence_stratification: true
  enable_temporal_weighting: true
  medical_specialty_boost: true
  
  # GPU-optimized search
  batch_search: true
  max_batch_size: 64  # Increased for GPU
  enable_parallel_search: true
  
  # Similarity thresholds optimized for medical content
  similarity_thresholds:
    tier1: 0.7
    tier2: 0.75
    tier3: 0.8

# Document processing configuration
processing:
  chunk_size: 512
  chunk_overlap: 100
  min_content_length: 50
  max_chunks_per_document: 20  # Increased for GPU
  
  # Enhanced medical processing
  enable_medical_entity_recognition: true
  enable_clinical_terminology_extraction: true
  enable_drug_name_recognition: true
  
  # GPU-optimized processing
  batch_size: 64  # Increased for GPU
  num_workers: 8  # Increased for GPU
  pin_memory: true
  
  # Tier balancing for MIRAGE optimization
  target_tier_ratios:
    tier1: 0.25  # Basic knowledge
    tier2: 0.55  # Clinical reasoning (most MIRAGE questions)
    tier3: 0.20  # Evidence-based

# Generation prompts optimized for MIRAGE
prompts:
  system: |
    You are an expert medical knowledge assistant trained to answer medical multiple-choice questions with precision and accuracy.
    
    YOUR EXPERTISE:
    - Comprehensive medical knowledge across all specialties
    - Systematic evaluation of clinical scenarios
    - Evidence-based medical reasoning
    - Accurate multiple-choice question analysis
    
    CRITICAL REQUIREMENTS:
    - MUST select one of the provided options (A, B, C, D, or E)
    - Base answers on established medical knowledge and clinical guidelines
    - Provide concise, accurate medical reasoning
    - Always conclude with "Answer: [LETTER]"
    - Focus on knowledge assessment, NOT treatment planning
    
    RESPONSE STRUCTURE:
    Analysis: [Brief evaluation of the medical question and key concepts]
    Reasoning: [Why the selected option is most accurate]
    Answer: [LETTER]

  tier1_pattern_recognition: |
    TIER 1: Basic Medical Knowledge & Pattern Recognition
    
    You are evaluating fundamental medical concepts including:
    ✓ Medical terminology and definitions
    ✓ Basic anatomy, physiology, and pathology  
    ✓ Fundamental disease mechanisms
    ✓ Basic pharmacology and drug classifications
    ✓ Medical terminology and nomenclature
    ✓ Essential medical facts and principles
    
    Approach: Identify key medical patterns and apply foundational knowledge.
    Format: Provide direct, factual analysis and select the correct answer.
    Required: Always end with "Answer: [LETTER]"

  tier2_clinical_reasoning: |
    TIER 2: Clinical Reasoning & Diagnostic Thinking
    
    You are applying systematic clinical analysis including:
    ✓ Clinical presentation evaluation
    ✓ Differential diagnosis processes  
    ✓ Pathophysiology analysis
    ✓ Clinical decision-making
    ✓ Patient scenario interpretation
    ✓ Disease progression and manifestations
    
    Approach: Use clinical reasoning to systematically evaluate each option.
    Format: Apply diagnostic thinking and clinical knowledge.
    Required: Always end with "Answer: [LETTER]"

  tier3_evidence_confirmation: |
    TIER 3: Evidence-Based Medicine & Guidelines
    
    You are referencing authoritative medical evidence including:
    ✓ Clinical research findings and studies
    ✓ Established medical guidelines and protocols
    ✓ Evidence-based treatment standards
    ✓ Outcomes research and prognostic data
    ✓ Best practice recommendations
    ✓ Consensus statements and expert opinions
    
    Approach: Confirm answers using the strongest available medical evidence.
    Format: Reference evidence-based standards and authoritative sources.
    Required: Always end with "Answer: [LETTER]"

# Evaluation configuration
evaluation:
  enable_medical_validation: true
  check_medical_terminology: true
  validate_drug_interactions: false  # Disabled for performance
  enable_clinical_reasoning_check: true

# Logging configuration
logging:
  level: "INFO"
  format: "{time:YYYY-MM-DD HH:mm:ss} | {level} | {name} | {message}"
  file_rotation: "100 MB"
  
  # GPU-specific logging
  log_gpu_memory: true
  log_inference_times: true

# Performance optimization for GPU
performance:
  # Memory management
  gpu_memory_fraction: 0.8
  enable_memory_growth: true
  allow_memory_growth: true
  
  # Compute optimizations
  enable_mixed_precision: true
  enable_tf32: true  # For RTX 4090
  enable_cudnn_benchmark: true
  
  # Parallel processing
  max_concurrent_requests: 16  # Increased for GPU
  enable_async_processing: true
  
  # Cache settings
  enable_model_cache: true
  cache_size_mb: 2048  # 2GB cache for GPU

generation:
  # Ensure consistent answer format
  enforce_answer_format: true
  answer_patterns:
    - "Answer: A"
    - "Answer: B" 
    - "Answer: C"
    - "Answer: D"
    - "Answer: E"
  
  # Temperature settings for medical accuracy
  temperature: 0.1  # Very low for consistent medical answers
  max_tokens: 300   # Shorter responses for efficiency
  
  # Stop sequences to ensure proper format
  stop_sequences:
    - "Question:"
    - "Next question"
    - "\n\nQuestion"

# Environment-specific settings
environment:
  type: "runpod_gpu"
  gpu_optimization: true
  cuda_device: 0
  tensor_parallel_size: 1