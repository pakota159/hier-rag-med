# root config.yaml
# HierRAGMed Configuration - M1 MacBook Pro Optimized

# Data directory
data_dir: data

# Model configurations
models:
  embedding:
    name: sentence-transformers/all-MiniLM-L6-v2
    device: mps  # M1 GPU acceleration
    batch_size: 16  # Reduced for M1 memory
  llm:
    name: mistral:7b-instruct  # Full model name with tag
    temperature: 0.7
    context_window: 4096

# Retrieval configurations
retrieval:
  top_k: 5
  hybrid_search: true
  alpha: 0.5

# Document processing configurations
processing:
  chunk_size: 512  # Smaller chunks for M1
  chunk_overlap: 100

# System prompts
prompts:
  system: |
    You are a helpful medical assistant. Use the provided context to answer the question accurately and concisely.
    If you cannot find the answer in the context, say so and do not make up information.
    Always prioritize patient safety and medical accuracy in your responses.
  system_with_citations: |
    You are a helpful medical assistant. Use the provided context to answer the question accurately and concisely.
    Cite your sources using the provided document numbers (e.g., [1], [2]).
    If you cannot find the answer in the context, say so and do not make up information.
    Always prioritize patient safety and medical accuracy in your responses.

# Web interface configurations
web:
  host: 0.0.0.0
  port: 8000
  cors_origins: ["*"]